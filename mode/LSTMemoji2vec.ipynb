{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMemoji2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hy-iNBLrQYmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVkgtML5QcFa",
        "colab_type": "code",
        "outputId": "9f4c20c5-64c9-446e-8f34-98cb93a40491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os  \n",
        "os.chdir('/content/')  \n",
        "!git clone https://github.com/ruelj2/Google_drive.git  \n",
        "\n",
        "from Google_drive.handle import Google_drive  \n",
        "Gd = Google_drive()  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.7MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.6MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 2.9MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 2.9MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.1MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.1MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 7.6MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 7.7MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 7.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 7.7MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 7.7MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 7.8MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 39.6MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 8.6MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 8.6MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 8.4MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 8.5MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 8.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 8.3MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 8.4MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 8.4MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 8.3MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 8.5MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 38.0MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 39.1MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 46.6MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 42.7MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 43.1MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 47.4MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 47.2MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 47.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 10.4MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 10.3MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 10.3MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 10.2MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 10.2MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 10.3MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 10.3MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 10.4MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 10.4MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 10.4MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 46.7MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 45.4MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 44.7MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 47.5MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 47.4MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 51.4MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 51.7MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 50.3MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 50.5MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 51.5MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 51.1MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 55.1MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 54.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 11.0MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 11.0MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 10.9MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 10.2MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 10.2MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 10.2MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 10.2MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 10.2MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 10.2MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 10.2MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 39.8MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 40.5MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 41.1MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 55.3MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 57.5MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 55.6MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 53.3MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 52.4MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 50.4MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 51.5MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 51.1MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 49.6MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 45.7MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 45.6MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 45.4MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 45.6MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 45.1MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 46.8MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 49.1MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 49.0MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 50.0MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 48.3MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 51.7MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 50.7MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 51.3MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.2MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCloning into 'Google_drive'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 106 (delta 32), reused 38 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 23.33 KiB | 2.59 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4RIWE7J1xeZP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "from pydrive.auth import GoogleAuth     \n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "Gd = Google_drive()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEe_IkR2xpzf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import = drive.CreateFile({'id':'1Y0LdeAzisVk-2BVnoqY9eR61Ax3R6rKD'})\n",
        "json_import.GetContentFile('GoogleNews-vectors-negative300.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGYeEZNyzs7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import1 = drive.CreateFile({'id':'1RQfHsaaFnEEz664YLKMxkTysRo8mAevS'})\n",
        "json_import1.GetContentFile('emoji2vec.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aqpmi2960fjL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import1 = drive.CreateFile({'id':'1DXnuatRulmjPV0T3lQPu8oyDw_2f34pK'})\n",
        "json_import1.GetContentFile('new_file.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l1HKaHoJQe8I",
        "colab_type": "code",
        "outputId": "7d3cbdef-1f8a-4787-ff45-6f7748c0c3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1Y0LdeAzisVk-2BVnoqY9eR61Ax3R6rKD'\n",
        "local_dir='/content'\n",
        "Gd.load_file(local_dir, file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GoogleNews-vectors-negative300.bin loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m5cxlJvrQlTa",
        "colab_type": "code",
        "outputId": "381d122a-df12-4def-e8cb-ed64df529a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1RQfHsaaFnEEz664YLKMxkTysRo8mAevS'\n",
        "local_dir='/content'\n",
        "Gd.load_file(local_dir,file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emoji2vec.bin loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63fObOyKQoUd",
        "colab_type": "code",
        "outputId": "4c04ddc5-ec8c-4d61-f269-0d8befb055e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1DXnuatRulmjPV0T3lQPu8oyDw_2f34pK'\n",
        "Gd.load_file(local_dir,file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new_file.txt loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2NCn4T0AQsgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_file(file_name):\n",
        "\tdata_list=[]\n",
        "\twith open(file_name,\"r\") as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\tline=line.strip()\n",
        "\t\t\tlabel=' '.join((line[line.find(\"[\")+1:line.find(\"]\")]).replace(',','').split())\n",
        "\t\t\ttext=line[line.find(\"'\")+1:line.find(\"')\")].strip()\n",
        "\t\t\tdata_list.append([label,text])\n",
        "\treturn data_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6L54XyswRO3x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name=\"new_file.txt\"\n",
        "psychExp_txt=read_file(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MepHZ4ZwRSLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w2v=gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ecnhYo4vT-kM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "e2v=gensim.models.KeyedVectors.load_word2vec_format('emoji2vec.bin',binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNApb5eJRz3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##consider n-gram features\n",
        "def ngram(token,n):\n",
        "  output=[]\n",
        "  for i in range(n-1,len(token)):\n",
        "    ngram=' '.join(token[i-n+1:i+1])\n",
        "    output.append(ngram)\n",
        "  return output  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8PHVi9lR3LL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_feature(text,nrange=(1,1)):\n",
        "  text_features=[]\n",
        "  text=text.lower()\n",
        "  text_alphanum=re.sub('[^a-z0-9#]',' ',text)\n",
        "  for n in range(nrange[0],nrange[1]+1):\n",
        "    text_features += ngram(text_alphanum.split(),n)\n",
        "  return(text_features)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MaC2L1zeR5YP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_label(item, name): \n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)): \n",
        "        if items[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "    \n",
        "    return label.strip()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbAhR0mYR7Yf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emotions = [\"😂\", '😱', \"😠\", \"😢\", \"😒\", \"😳\", \"😣\"]\n",
        "\n",
        "X_all = []\n",
        "Y_all = []\n",
        "for label, text in psychExp_txt:\n",
        "    Y_all.append(torch.LongTensor(list(map(float,label.split()))))\n",
        "    X_all.append(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yt8NmcHB_2uP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_all,Y_all,test_size=0.2,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQogS0WyhLzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_train=[]\n",
        "label_test=[]\n",
        "for i in Y_train:\n",
        "  label_train.append(torch.nonzero(i).squeeze())\n",
        "for i in Y_test:\n",
        "  label_test.append(torch.nonzero(i).squeeze())\n",
        "label_test=label_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3ehueZE9mDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build vocabulary \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X_train)\n",
        "vocab=vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ZQ3CCn796Vk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_train=[]\n",
        "for i in X_train:\n",
        "  b=[]\n",
        "  i=create_feature(i)\n",
        "  for j in i:\n",
        "    try:\n",
        "      b.append(vocab.index(j))\n",
        "    except ValueError:\n",
        "      vocab.append(j)\n",
        "      b.append(len(vocab)-1)\n",
        "  sentence_train.append(torch.LongTensor(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FzQ7K6IM31Kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_test=[]\n",
        "for i in X_test:\n",
        "  b=[]\n",
        "  i=create_feature(i)\n",
        "  for j in i:\n",
        "    try:\n",
        "      b.append(vocab.index(j))\n",
        "    except ValueError:\n",
        "      b\n",
        "  sentence_test.append(torch.LongTensor(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41XiRvrF9_Ku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights=np.zeros((len(vocab),300))\n",
        "for i,word in enumerate(vocab):\n",
        "  try:\n",
        "    weights[i]=w2v[word]\n",
        "  except KeyError:\n",
        "    weights[i] = np.random.normal(scale=0.6, size=(300, ))\n",
        "weights=torch.FloatTensor(weights)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "srcFCxrTAmHw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights_emoji=np.zeros((len(emotions),300))\n",
        "for i,emoji in enumerate(emotions):\n",
        "  if emoji in e2v:\n",
        "    weights_emoji[i]=e2v[emoji]\n",
        "weights_emoji=torch.FloatTensor(weights_emoji)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSPTssHGlLG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self,weight_matrix_of_word,weight_matrix_of_emoji,num_embeddings,hidden_dim,embedding_dim,target_size,batch_size=1):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.batch_size=batch_size\n",
        "    self.embedding_word=nn.Embedding.from_pretrained(weight_matrix_of_word)\n",
        "    self.embedding_emoji=nn.Embedding.from_pretrained(weight_matrix_of_emoji,freeze=False)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.hidden=self.init_hidden()\n",
        "    self.linear=nn.Linear(hidden_dim,target_size)\n",
        "    self.cos=nn.CosineSimilarity(dim=0)\n",
        "  def init_hidden(self):\n",
        "    return(Variable(torch.zeros(1,self.batch_size,self.hidden_dim)),Variable(torch.zeros(1,self.batch_size,self.hidden_dim)))\n",
        "  def forward(self,sentence):\n",
        "    embeds_word=self.embedding_word(sentence)\n",
        "    embeds_emoji=(self.embedding_emoji).weight\n",
        "    x=embeds_word.view(self.batch_size,len(sentence),-1)\n",
        "    lstm_out,self.hidden=self.lstm(x,self.hidden)\n",
        "    a=torch.zeros(self.batch_size,len(embeds_emoji))\n",
        "    output=self.linear(lstm_out[:,-1,:])\n",
        "    for i,j in enumerate(embeds_emoji):\n",
        "      for p,q in enumerate(output):\n",
        "        a[p][i]=self.cos(q,j)\n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IaoCEr26QHQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(test_text,test_label,Model,batch_size=1):\n",
        "  total=len(test_label)\n",
        "  correct=0\n",
        "  for sentence,labels in zip(test_text,test_label):\n",
        "    output=torch.argmax(Model(sentence),dim=1)\n",
        "    correct += (output==labels).sum()\n",
        "  return float(correct)/total  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVtK041iBhFF",
        "colab_type": "code",
        "outputId": "2a69a76f-a3f0-4b53-c353-cace4ec39940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "### Train the model\n",
        "model=LSTMClassifier(weights,weights_emoji,len(vocab),200,300,300)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01,weight_decay=0)\n",
        "epoch_accuracies = []\n",
        "best_accuracy=0\n",
        "for epoch in range(1000):\n",
        "  i=0\n",
        "  for sentence,labels in zip(sentence_train,label_train):\n",
        "    i=i+1\n",
        "    optimizer.zero_grad()\n",
        "    model.hidden=model.init_hidden()\n",
        "    outputs=model(sentence)\n",
        "    labels=labels.unsqueeze(dim=0)\n",
        "    loss=loss_function(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1)%1000==0:\n",
        "              print ('Epoch: [%d/%d], Step: [%d/%d] , Loss: %.4f, Dev: %.4f' \n",
        "                     % (epoch+1, 1000, i+1, len(sentence_train), \n",
        "                        loss.data, accuracy(sentence_train,label_train,model)))\n",
        "  epoch_accuracies.append(accuracy(sentence_test,label_test,model))\n",
        "  if epoch_accuracies[-1] > best_accuracy:\n",
        "    best_accuracy = epoch_accuracies[-1]\n",
        "    best_epoch = epoch\n",
        "  if(epoch>=5 and epoch_accuracies[-1]<=epoch_accuracies[-5]):\n",
        "    break        \n",
        "  # TODO: implement early stopping here      \n",
        "  print(best_accuracy, best_epoch)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/1000], Step: [1000/5984] , Loss: 2.0803, Dev: 0.1611\n",
            "Epoch: [1/1000], Step: [2000/5984] , Loss: 1.9066, Dev: 0.2072\n",
            "Epoch: [1/1000], Step: [3000/5984] , Loss: 1.8041, Dev: 0.2116\n",
            "Epoch: [1/1000], Step: [4000/5984] , Loss: 1.9309, Dev: 0.2543\n",
            "Epoch: [1/1000], Step: [5000/5984] , Loss: 1.6464, Dev: 0.2908\n",
            "0.28475935828877 0\n",
            "Epoch: [2/1000], Step: [1000/5984] , Loss: 2.0626, Dev: 0.3341\n",
            "Epoch: [2/1000], Step: [2000/5984] , Loss: 1.2952, Dev: 0.3336\n",
            "Epoch: [2/1000], Step: [3000/5984] , Loss: 1.4983, Dev: 0.3314\n",
            "Epoch: [2/1000], Step: [4000/5984] , Loss: 1.6821, Dev: 0.3690\n",
            "Epoch: [2/1000], Step: [5000/5984] , Loss: 2.5497, Dev: 0.3852\n",
            "0.3442513368983957 1\n",
            "Epoch: [3/1000], Step: [1000/5984] , Loss: 2.0055, Dev: 0.3864\n",
            "Epoch: [3/1000], Step: [2000/5984] , Loss: 1.1658, Dev: 0.3491\n",
            "Epoch: [3/1000], Step: [3000/5984] , Loss: 1.3685, Dev: 0.3695\n",
            "Epoch: [3/1000], Step: [4000/5984] , Loss: 1.6890, Dev: 0.3496\n",
            "Epoch: [3/1000], Step: [5000/5984] , Loss: 2.2823, Dev: 0.2500\n",
            "0.3442513368983957 1\n",
            "Epoch: [4/1000], Step: [1000/5984] , Loss: 1.8929, Dev: 0.4091\n",
            "Epoch: [4/1000], Step: [2000/5984] , Loss: 1.1187, Dev: 0.3058\n",
            "Epoch: [4/1000], Step: [3000/5984] , Loss: 1.3134, Dev: 0.3854\n",
            "Epoch: [4/1000], Step: [4000/5984] , Loss: 1.5799, Dev: 0.3852\n",
            "Epoch: [4/1000], Step: [5000/5984] , Loss: 2.2745, Dev: 0.2950\n",
            "0.3589572192513369 3\n",
            "Epoch: [5/1000], Step: [1000/5984] , Loss: 1.9766, Dev: 0.3585\n",
            "Epoch: [5/1000], Step: [2000/5984] , Loss: 1.1369, Dev: 0.2520\n",
            "Epoch: [5/1000], Step: [3000/5984] , Loss: 1.2767, Dev: 0.3777\n",
            "Epoch: [5/1000], Step: [4000/5984] , Loss: 1.6966, Dev: 0.2960\n",
            "Epoch: [5/1000], Step: [5000/5984] , Loss: 2.4631, Dev: 0.3003\n",
            "0.3589572192513369 3\n",
            "Epoch: [6/1000], Step: [1000/5984] , Loss: 2.0527, Dev: 0.3506\n",
            "Epoch: [6/1000], Step: [2000/5984] , Loss: 1.0766, Dev: 0.2995\n",
            "Epoch: [6/1000], Step: [3000/5984] , Loss: 1.2683, Dev: 0.3690\n",
            "Epoch: [6/1000], Step: [4000/5984] , Loss: 1.4242, Dev: 0.3996\n",
            "Epoch: [6/1000], Step: [5000/5984] , Loss: 2.4995, Dev: 0.2430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pbBU-gE7IZWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metrics(test_text,test_label,Model,batch_size=1):\n",
        "  a=np.array(test_label)\n",
        "  b=np.zeros(len(test_label))\n",
        "  for i,sentence in enumerate(test_text):\n",
        "    predict=torch.argmax(Model(sentence))\n",
        "    b[i]=predict\n",
        "  F1=f1_score(a,b,average=None)\n",
        "  F1_total = f1_score(a,b,average='macro')\n",
        "  rscore=recall_score(a,b,average=None)\n",
        "  rscore_total=recall_score(a,b,average='macro')\n",
        "  pscore=precision_score(a,b,average=None)\n",
        "  pscore_total=precision_score(a,b,average='macro')\n",
        "  print(\"F1:\"+str(F1))\n",
        "  print(\"recall_score:\"+str(rscore))\n",
        "  print(\"precision_score:\"+str(pscore))\n",
        "  print(\"F1_toal:\"+str(F1_total))\n",
        "  print(\"rscore_total:\"+str(rscore_total))\n",
        "  print(\"pscore_total:\"+str(pscore_total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79lIU0JoIcB8",
        "colab_type": "code",
        "outputId": "c2bf8385-4111-473a-99fc-b7a77265f8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "metrics(sentence_test,label_test,model,batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1:[0.42590286 0.2877193  0.31799163 0.35616438 0.34343434 0.25657895\n",
            " 0.27700831]\n",
            "recall_score:[0.81042654 0.18303571 0.33333333 0.29147982 0.35233161 0.1959799\n",
            " 0.2293578 ]\n",
            "precision_score:[0.28885135 0.67213115 0.304      0.45774648 0.33497537 0.37142857\n",
            " 0.34965035]\n",
            "F1_toal:0.3235428255596459\n",
            "rscore_total:0.3422778160587789\n",
            "pscore_total:0.3969690383289462\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}