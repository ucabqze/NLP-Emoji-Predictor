{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMbaseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OojDZ3CljyIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7EHF6n2ij0eD",
        "colab_type": "code",
        "outputId": "4cba42a1-7221-422c-b0db-68cc6f51d001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os  \n",
        "os.chdir('/content/')  \n",
        "!git clone https://github.com/ruelj2/Google_drive.git  \n",
        "\n",
        "from Google_drive.handle import Google_drive  \n",
        "Gd = Google_drive()  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Google_drive' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0II6T55Zj3gM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "from pydrive.auth import GoogleAuth     \n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "Gd = Google_drive()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q51Ygt6Oj5Q0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import = drive.Creajson_import1 = drive.CreateFile({'id':'1RQfHsaaFnEEz664YLKMxkTysRo8mAevS'})\n",
        "json_import.GetContentFile('GoogleNews-vectors-negative300.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2i0GTlQnip7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import1 = drive.CreateFile({'id':'1RQfHsaaFnEEz664YLKMxkTysRo8mAevS'})\n",
        "json_import1.GetContentFile('emoji2vec.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbTTpoMHiwIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import1 = drive.CreateFile({'id':'1DXnuatRulmjPV0T3lQPu8oyDw_2f34pK'})\n",
        "json_import1.GetContentFile('new_file.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAIi0m_Tiz9W",
        "colab_type": "code",
        "outputId": "b470a309-5626-4b87-f68e-13ed804022e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1Y0LdeAzisVk-2BVnoqY9eR61Ax3R6rKD'\n",
        "local_dir='/content'\n",
        "Gd.load_file(local_dir, file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GoogleNews-vectors-negative300.bin loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tAM7eFr-j8sS",
        "colab_type": "code",
        "outputId": "f630a986-409b-4325-a34b-263b3c592194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1RQfHsaaFnEEz664YLKMxkTysRo8mAevS'\n",
        "local_dir='/content'\n",
        "Gd.load_file(local_dir,file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emoji2vec.bin loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yiPN0CuSi7Vd",
        "colab_type": "code",
        "outputId": "f0687f08-b47d-4821-8c50-40097a84fdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1DXnuatRulmjPV0T3lQPu8oyDw_2f34pK'\n",
        "Gd.load_file(local_dir,file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new_file.txt loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WSkG2zACj9Pd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_file(file_name):\n",
        "\tdata_list=[]\n",
        "\twith open(file_name,\"r\") as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\tline=line.strip()\n",
        "\t\t\tlabel=' '.join((line[line.find(\"[\")+1:line.find(\"]\")]).replace(',','').split())\n",
        "\t\t\ttext=line[line.find(\"'\")+1:line.find(\"')\")].strip()\n",
        "\t\t\tdata_list.append([label,text])\n",
        "\treturn data_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHbgFSFjkKI7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name=\"new_file.txt\"\n",
        "psychExp_txt=read_file(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtYUq0LbkL_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##consider n-gram features\n",
        "def ngram(token,n):\n",
        "  output=[]\n",
        "  for i in range(n-1,len(token)):\n",
        "    ngram=' '.join(token[i-n+1:i+1])\n",
        "    output.append(ngram)\n",
        "  return output  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fgSmV7h7kON9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_feature(text,nrange=(1,1)):\n",
        "  text_features=[]\n",
        "  text=text.lower()\n",
        "  text_alphanum=re.sub('[^a-z0-9#]',' ',text)\n",
        "  for n in range(nrange[0],nrange[1]+1):\n",
        "    text_features += ngram(text_alphanum.split(),n)\n",
        "  return(text_features)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3N54sTrkP9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_label(item, name): \n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)): \n",
        "        if items[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "    \n",
        "    return label.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4DoNd5FkRqH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emotions = [\"ðŸ˜‚\", 'ðŸ˜±', \"ðŸ˜ \", \"ðŸ˜¢\", \"ðŸ˜’\", \"ðŸ˜³\", \"ðŸ˜£\"]\n",
        "\n",
        "X_all = []\n",
        "Y_all = []\n",
        "for label, text in psychExp_txt:\n",
        "    Y_all.append(torch.LongTensor(list(map(float,label.split()))))\n",
        "    X_all.append(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6lyNbFkkTPI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_all,Y_all,test_size=0.2,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihxQtCTxkXJ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_train=[]\n",
        "label_test=[]\n",
        "for i in Y_train:\n",
        "  label_train.append(torch.nonzero(i).squeeze())\n",
        "for i in Y_test:\n",
        "  label_test.append(torch.nonzero(i).squeeze())\n",
        "label_test=label_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTXVYT2WkY9I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build vocabulary \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X_train)\n",
        "vocab=vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuEw44VekaoD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_train=[]\n",
        "for i in X_train:\n",
        "  b=[]\n",
        "  i=create_feature(i)\n",
        "  for j in i:\n",
        "    try:\n",
        "      b.append(vocab.index(j))\n",
        "    except ValueError:\n",
        "      vocab.append(j)\n",
        "      b.append(len(vocab)-1)\n",
        "  sentence_train.append(torch.LongTensor(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjNo7Y47kcPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_test=[]\n",
        "for i in X_test:\n",
        "  b=[]\n",
        "  i=create_feature(i)\n",
        "  for j in i:\n",
        "    try:\n",
        "      b.append(vocab.index(j))\n",
        "    except ValueError:\n",
        "      b\n",
        "  sentence_test.append(torch.LongTensor(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOauhXI7keF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self,num_embeddings,hidden_dim,embedding_dim,target_size,batch_size=1):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.batch_size=batch_size\n",
        "    self.embedding=nn.Embedding(num_embeddings,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.hidden=self.init_hidden()\n",
        "    self.linear=nn.Linear(hidden_dim,target_size)\n",
        "    self.cos=nn.CosineSimilarity(dim=0)\n",
        "  def init_hidden(self):\n",
        "    return(Variable(torch.zeros(1,self.batch_size,self.hidden_dim)),Variable(torch.zeros(1,self.batch_size,self.hidden_dim)))\n",
        "  def forward(self,sentence):\n",
        "    embeds_word=self.embedding(sentence)\n",
        "    x=embeds_word.view(self.batch_size,len(sentence),-1)\n",
        "    lstm_out,self.hidden=self.lstm(x,self.hidden)\n",
        "    output=self.linear(lstm_out[:,-1,:])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQG7SoEBkgN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(test_text,test_label,Model,batch_size=1):\n",
        "  total=len(test_label)\n",
        "  correct=0\n",
        "  for sentence,labels in zip(test_text,test_label):\n",
        "    output=torch.argmax(Model(sentence))\n",
        "    correct += (output==labels).sum()\n",
        "  return float(correct)/total  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W36s-Ml9HkZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metrics(test_text,test_label,Model,batch_size=1):\n",
        "  a=np.array(test_label)\n",
        "  b=np.zeros(len(test_label))\n",
        "  for i,sentence in enumerate(test_text):\n",
        "    predict=torch.argmax(Model(sentence))\n",
        "    b[i]=predict\n",
        "  F1=f1_score(a,b,average=None)\n",
        "  F1_total = f1_score(a,b,average='macro')\n",
        "  rscore=recall_score(a,b,average=None)\n",
        "  rscore_total=recall_score(a,b,average='macro')\n",
        "  pscore=precision_score(a,b,average=None)\n",
        "  pscore_total=precision_score(a,b,average='macro')\n",
        "  print(\"F1:\"+str(F1))\n",
        "  print(\"recall_score:\"+str(rscore))\n",
        "  print(\"precision_score:\"+str(pscore))\n",
        "  print(\"F1_toal:\"+str(F1_total))\n",
        "  print(\"rscore_total:\"+str(rscore_total))\n",
        "  print(\"pscore_total:\"+str(pscore_total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDY17ZA1lWLO",
        "colab_type": "code",
        "outputId": "87c8345a-047e-4771-df7b-9b94683230c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        }
      },
      "cell_type": "code",
      "source": [
        "### Train the model\n",
        "model=LSTMClassifier(len(vocab),30,50,7)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.1,weight_decay=0)\n",
        "epoch_accuracies = []\n",
        "best_accuracy=0\n",
        "for epoch in range(1000):\n",
        "  i=0\n",
        "  for sentence,labels in zip(sentence_train,label_train):\n",
        "    i=i+1\n",
        "    optimizer.zero_grad()\n",
        "    model.hidden=model.init_hidden()\n",
        "    outputs=model(sentence)\n",
        "    labels=labels.unsqueeze(dim=0)\n",
        "    loss=loss_function(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1)%1000==0:\n",
        "              print ('Epoch: [%d/%d], Step: [%d/%d] , Loss: %.4f, Dev: %.4f' \n",
        "                     % (epoch+1, 1000, i+1, len(sentence_train)//32, \n",
        "                        loss.data, accuracy(sentence_train,label_train,model)))\n",
        "  epoch_accuracies.append(accuracy(sentence_test,label_test,model))\n",
        "  if epoch_accuracies[-1] > best_accuracy:\n",
        "    best_accuracy = epoch_accuracies[-1]\n",
        "    best_epoch = epoch\n",
        "  if(epoch>=10 and epoch_accuracies[-1]<=epoch_accuracies[-10]):\n",
        "    break        \n",
        "  # TODO: implement early stopping here      \n",
        "  print(best_accuracy, best_epoch)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/1000], Step: [1000/187] , Loss: 2.0865, Dev: 0.2034\n",
            "Epoch: [1/1000], Step: [2000/187] , Loss: 1.0360, Dev: 0.2316\n",
            "Epoch: [1/1000], Step: [3000/187] , Loss: 1.8631, Dev: 0.2612\n",
            "Epoch: [1/1000], Step: [4000/187] , Loss: 2.1101, Dev: 0.2781\n",
            "Epoch: [1/1000], Step: [5000/187] , Loss: 1.5364, Dev: 0.3016\n",
            "0.22393048128342247 0\n",
            "Epoch: [2/1000], Step: [1000/187] , Loss: 2.5301, Dev: 0.3386\n",
            "Epoch: [2/1000], Step: [2000/187] , Loss: 0.8966, Dev: 0.3484\n",
            "Epoch: [2/1000], Step: [3000/187] , Loss: 1.6570, Dev: 0.3651\n",
            "Epoch: [2/1000], Step: [4000/187] , Loss: 1.4227, Dev: 0.3770\n",
            "Epoch: [2/1000], Step: [5000/187] , Loss: 1.9282, Dev: 0.3964\n",
            "0.26537433155080214 1\n",
            "Epoch: [3/1000], Step: [1000/187] , Loss: 2.3943, Dev: 0.4124\n",
            "Epoch: [3/1000], Step: [2000/187] , Loss: 0.4451, Dev: 0.4236\n",
            "Epoch: [3/1000], Step: [3000/187] , Loss: 1.4301, Dev: 0.4230\n",
            "Epoch: [3/1000], Step: [4000/187] , Loss: 1.4123, Dev: 0.4462\n",
            "Epoch: [3/1000], Step: [5000/187] , Loss: 3.2956, Dev: 0.4490\n",
            "0.2820855614973262 2\n",
            "Epoch: [4/1000], Step: [1000/187] , Loss: 1.5809, Dev: 0.4696\n",
            "Epoch: [4/1000], Step: [2000/187] , Loss: 0.1601, Dev: 0.4669\n",
            "Epoch: [4/1000], Step: [3000/187] , Loss: 1.1153, Dev: 0.4995\n",
            "Epoch: [4/1000], Step: [4000/187] , Loss: 0.9895, Dev: 0.4848\n",
            "Epoch: [4/1000], Step: [5000/187] , Loss: 1.4327, Dev: 0.4761\n",
            "0.2820855614973262 2\n",
            "Epoch: [5/1000], Step: [1000/187] , Loss: 1.5605, Dev: 0.5105\n",
            "Epoch: [5/1000], Step: [2000/187] , Loss: 0.0887, Dev: 0.5197\n",
            "Epoch: [5/1000], Step: [3000/187] , Loss: 1.6138, Dev: 0.5418\n",
            "Epoch: [5/1000], Step: [4000/187] , Loss: 1.1487, Dev: 0.5321\n",
            "Epoch: [5/1000], Step: [5000/187] , Loss: 1.8776, Dev: 0.5326\n",
            "0.2820855614973262 2\n",
            "Epoch: [6/1000], Step: [1000/187] , Loss: 0.9114, Dev: 0.5556\n",
            "Epoch: [6/1000], Step: [2000/187] , Loss: 0.0235, Dev: 0.5495\n",
            "Epoch: [6/1000], Step: [3000/187] , Loss: 2.5943, Dev: 0.5535\n",
            "Epoch: [6/1000], Step: [4000/187] , Loss: 0.6119, Dev: 0.5541\n",
            "Epoch: [6/1000], Step: [5000/187] , Loss: 0.5948, Dev: 0.5710\n",
            "0.2967914438502674 5\n",
            "Epoch: [7/1000], Step: [1000/187] , Loss: 3.0726, Dev: 0.5683\n",
            "Epoch: [7/1000], Step: [2000/187] , Loss: 0.0080, Dev: 0.5665\n",
            "Epoch: [7/1000], Step: [3000/187] , Loss: 1.7082, Dev: 0.5854\n",
            "Epoch: [7/1000], Step: [4000/187] , Loss: 0.4469, Dev: 0.5685\n",
            "Epoch: [7/1000], Step: [5000/187] , Loss: 1.1020, Dev: 0.5799\n",
            "0.30080213903743314 6\n",
            "Epoch: [8/1000], Step: [1000/187] , Loss: 0.6875, Dev: 0.6210\n",
            "Epoch: [8/1000], Step: [2000/187] , Loss: 0.0004, Dev: 0.6247\n",
            "Epoch: [8/1000], Step: [3000/187] , Loss: 1.4072, Dev: 0.6290\n",
            "Epoch: [8/1000], Step: [4000/187] , Loss: 0.3325, Dev: 0.6192\n",
            "Epoch: [8/1000], Step: [5000/187] , Loss: 0.1927, Dev: 0.6364\n",
            "0.30080213903743314 6\n",
            "Epoch: [9/1000], Step: [1000/187] , Loss: 1.3727, Dev: 0.6512\n",
            "Epoch: [9/1000], Step: [2000/187] , Loss: 0.0000, Dev: 0.6487\n",
            "Epoch: [9/1000], Step: [3000/187] , Loss: 0.2233, Dev: 0.6547\n",
            "Epoch: [9/1000], Step: [4000/187] , Loss: 0.3029, Dev: 0.6710\n",
            "Epoch: [9/1000], Step: [5000/187] , Loss: 0.0062, Dev: 0.6643\n",
            "0.30414438502673796 8\n",
            "Epoch: [10/1000], Step: [1000/187] , Loss: 0.1551, Dev: 0.6815\n",
            "Epoch: [10/1000], Step: [2000/187] , Loss: 0.0001, Dev: 0.6811\n",
            "Epoch: [10/1000], Step: [3000/187] , Loss: 0.3035, Dev: 0.6878\n",
            "Epoch: [10/1000], Step: [4000/187] , Loss: 0.3475, Dev: 0.6768\n",
            "Epoch: [10/1000], Step: [5000/187] , Loss: 0.6543, Dev: 0.6832\n",
            "0.30414438502673796 8\n",
            "Epoch: [11/1000], Step: [1000/187] , Loss: 0.8171, Dev: 0.7074\n",
            "Epoch: [11/1000], Step: [2000/187] , Loss: 0.0072, Dev: 0.6974\n",
            "Epoch: [11/1000], Step: [3000/187] , Loss: 0.5731, Dev: 0.7007\n",
            "Epoch: [11/1000], Step: [4000/187] , Loss: 0.2673, Dev: 0.6999\n",
            "Epoch: [11/1000], Step: [5000/187] , Loss: 0.7826, Dev: 0.7012\n",
            "0.30614973262032086 10\n",
            "Epoch: [12/1000], Step: [1000/187] , Loss: 0.6254, Dev: 0.7111\n",
            "Epoch: [12/1000], Step: [2000/187] , Loss: 0.0003, Dev: 0.7199\n",
            "Epoch: [12/1000], Step: [3000/187] , Loss: 0.2021, Dev: 0.7000\n",
            "Epoch: [12/1000], Step: [4000/187] , Loss: 0.0637, Dev: 0.7172\n",
            "Epoch: [12/1000], Step: [5000/187] , Loss: 0.1711, Dev: 0.7134\n",
            "0.3088235294117647 11\n",
            "Epoch: [13/1000], Step: [1000/187] , Loss: 0.1458, Dev: 0.7076\n",
            "Epoch: [13/1000], Step: [2000/187] , Loss: 0.0000, Dev: 0.7069\n",
            "Epoch: [13/1000], Step: [3000/187] , Loss: 0.2062, Dev: 0.7066\n",
            "Epoch: [13/1000], Step: [4000/187] , Loss: 0.1871, Dev: 0.7124\n",
            "Epoch: [13/1000], Step: [5000/187] , Loss: 1.4937, Dev: 0.7074\n",
            "0.3088235294117647 11\n",
            "Epoch: [14/1000], Step: [1000/187] , Loss: 0.6570, Dev: 0.7079\n",
            "Epoch: [14/1000], Step: [2000/187] , Loss: 0.0001, Dev: 0.7234\n",
            "Epoch: [14/1000], Step: [3000/187] , Loss: 0.2596, Dev: 0.7216\n",
            "Epoch: [14/1000], Step: [4000/187] , Loss: 0.5111, Dev: 0.7223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a_iY-uHfliha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "41e110d5-d5e7-4928-93d3-88f449882e61"
      },
      "cell_type": "code",
      "source": [
        " metrics(sentence_test,label_test,model,batch_size=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1:[0.37250554 0.36979167 0.22988506 0.29450549 0.3236715  0.27777778\n",
            " 0.26128266]\n",
            "recall_score:[0.39810427 0.31696429 0.21929825 0.30044843 0.34715026 0.30150754\n",
            " 0.25229358]\n",
            "precision_score:[0.35       0.44375    0.24154589 0.2887931  0.30316742 0.25751073\n",
            " 0.27093596]\n",
            "F1_toal:0.3042028139393623\n",
            "rscore_total:0.3051095145659842\n",
            "pscore_total:0.30795758688391844\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}