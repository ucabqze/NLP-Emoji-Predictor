{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNbaseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1t1vhhjU-V3f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJy79dGO-bUT",
        "colab_type": "code",
        "outputId": "d5e32624-5f7d-4172-c316-634e8657c713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os  \n",
        "os.chdir('/content/')  \n",
        "!git clone https://github.com/ruelj2/Google_drive.git  \n",
        "\n",
        "from Google_drive.handle import Google_drive  \n",
        "Gd = Google_drive()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.9MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.0MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.0MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.0MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.0MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.0MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.0MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 34.2MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.4MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.4MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.4MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.4MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.4MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 10.2MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.3MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.3MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.3MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.7MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 37.8MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 37.2MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 40.7MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 38.3MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 38.4MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 42.4MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 42.6MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 43.4MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 13.0MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 12.9MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 12.9MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 12.9MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 12.7MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 12.7MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 12.7MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 12.7MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 12.6MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 12.6MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 39.5MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 38.0MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 39.5MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 40.7MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 41.5MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 45.9MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 46.7MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 46.2MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 46.5MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 46.7MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 46.9MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 50.5MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 50.0MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 49.1MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 15.4MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 15.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 13.6MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 13.5MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 13.4MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 13.5MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 13.5MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 13.3MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 13.3MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 13.3MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 33.4MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 34.9MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 45.7MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 47.7MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 47.7MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 47.9MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 47.7MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 49.5MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 50.8MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 48.1MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 47.1MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 43.0MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 42.9MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 43.1MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 42.6MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 42.0MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 42.6MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 42.9MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 43.0MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 44.5MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 44.7MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 50.6MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 50.7MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 50.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 19.5MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCloning into 'Google_drive'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 106 (delta 32), reused 38 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 23.33 KiB | 4.67 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kSTf-9z0-lKv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "from pydrive.auth import GoogleAuth     \n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "Gd = Google_drive()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jygHZvue-oz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_import1 = drive.CreateFile({'id':'1DXnuatRulmjPV0T3lQPu8oyDw_2f34pK'})\n",
        "json_import1.GetContentFile('new_file.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8n68vxPn-r0J",
        "colab_type": "code",
        "outputId": "0514e4ad-bb5e-4c23-fb43-551e54c3766c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "file_ID='1DXnuatRulmjPV0T3lQPu8oyDw_2f34pK'\n",
        "Gd.load_file('/content',file_ID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new_file.txt loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EtcTCByN-vV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_file(file_name):\n",
        "\tdata_list=[]\n",
        "\twith open(file_name,\"r\") as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\tline=line.strip()\n",
        "\t\t\tlabel=' '.join((line[line.find(\"[\")+1:line.find(\"]\")]).replace(',','').split())\n",
        "\t\t\ttext=line[line.find(\"'\")+1:line.find(\"')\")].strip()\n",
        "\t\t\tdata_list.append([label,text])\n",
        "\treturn data_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8CZhFspAOZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name=\"new_file.txt\"\n",
        "psychExp_txt=read_file(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXOOkpyfAYK_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##consider n-gram features\n",
        "def ngram(token,n):\n",
        "  output=[]\n",
        "  for i in range(n-1,len(token)):\n",
        "    ngram=' '.join(token[i-n+1:i+1])\n",
        "    output.append(ngram)\n",
        "  return output  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSHDvLa_Cs21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_feature(text,nrange=(1,1)):\n",
        "  text_features=[]\n",
        "  text=text.lower()\n",
        "  text_alphanum=re.sub('[^a-z0-9#]',' ',text)\n",
        "  for n in range(nrange[0], nrange[1]+1):\n",
        "    text_features += ngram(text_alphanum.split(),n)\n",
        "  return(text_features)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Znu07VZtEOVS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_label(item, name): \n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)): \n",
        "        if items[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "    \n",
        "    return label.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3ubae0bEcDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emotions = [\"😂\", \"😱\", \"😠\", \"😢\", \"😒\", \"😳\", \"😣\"]\n",
        "\n",
        "X_all = []\n",
        "Y_all = []\n",
        "for label, text in psychExp_txt:\n",
        "    Y_all.append(torch.LongTensor(list(map(float,label.split()))))\n",
        "    X_all.append(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pciim8vpEcqB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_all,Y_all,test_size=0.2,random_state=123) ### random_state = 123?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SuL0tdz3ExUl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_train=[]\n",
        "label_test=[]\n",
        "for i in Y_train:\n",
        "  label_train.append(torch.nonzero(i).squeeze())\n",
        "for i in Y_test:\n",
        "  label_test.append(torch.nonzero(i).squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2kXjr1XF_8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build vocabulary \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X_train)\n",
        "vocab=vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPRibM-xGq_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_train=[]\n",
        "for i in X_train:\n",
        "  b=[]\n",
        "  i=create_feature(i)\n",
        "  for j in i:\n",
        "    try:\n",
        "      b.append(vocab.index(j))\n",
        "    except ValueError:\n",
        "      vocab.append(j)\n",
        "      b.append(len(vocab)-1)\n",
        "  sentence_train.append(torch.LongTensor(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vw8E9TU67EUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_test=[]\n",
        "for i in X_test:\n",
        "  b=[]\n",
        "  i=create_feature(i)\n",
        "  for j in i:\n",
        "    try:\n",
        "      b.append(vocab.index(j))\n",
        "    except ValueError:\n",
        "      b\n",
        "  sentence_test.append(torch.LongTensor(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDZOwUzSojs-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(test_text,test_label,Model,batch_size=1):\n",
        "  total=len(test_label)\n",
        "  correct=0\n",
        "  for sentence,labels in zip(test_text,test_label):\n",
        "    output=torch.argmax(Model(sentence))\n",
        "    correct += (output==labels).sum()\n",
        "  return float(correct)/total  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sv0cIQEEHNRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metrics(test_text,test_label,Model,batch_size=1):\n",
        "  a=np.array(test_label)\n",
        "  b=np.zeros(len(test_label))\n",
        "  for i,sentence in enumerate(test_text):\n",
        "    predict=torch.argmax(Model(sentence))\n",
        "    b[i]=predict\n",
        "  F1=f1_score(a,b,average=None)\n",
        "  F1_total = f1_score(a,b,average='macro')\n",
        "  rscore=recall_score(a,b,average=None)\n",
        "  rscore_total=recall_score(a,b,average='macro')\n",
        "  pscore=precision_score(a,b,average=None)\n",
        "  pscore_total=precision_score(a,b,average='macro')\n",
        "  print(\"F1:\"+str(F1))\n",
        "  print(\"recall_score:\"+str(rscore))\n",
        "  print(\"precision_score:\"+str(pscore))\n",
        "  print(\"F1_toal:\"+str(F1_total))\n",
        "  print(\"rscore_total:\"+str(rscore_total))\n",
        "  print(\"pscore_total:\"+str(pscore_total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTqz1bEOSTrx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self,num_embeddings, embedding_dim, hidden_dim,target_size,kernel_size):\n",
        "      super(CNNClassifier, self).__init__()\n",
        "      self.kernel_size=kernel_size\n",
        "      self.embedding_word=nn.Embedding(num_embeddings,embedding_dim)\n",
        "      self.conv1=nn.Conv1d(embedding_dim,hidden_dim,kernel_size)\n",
        "      self.conv2=nn.Conv1d(embedding_dim,hidden_dim,1)\n",
        "      \n",
        "      self.output=nn.Linear(hidden_dim,target_size)\n",
        "    \n",
        "\n",
        "  def forward(self,sentence):\n",
        "    x=self.embedding_word(sentence).view(1,len(sentence),-1).transpose(1,2)\n",
        "    if(len(sentence)>1):\n",
        "      c=self.conv1(x)\n",
        "      pool1=nn.MaxPool1d(len(sentence)-self.kernel_size+1)\n",
        "    else:\n",
        "      c=self.conv2(x)\n",
        "      pool1=nn.MaxPool1d(1)\n",
        "    c=F.relu(c)  \n",
        "    p=pool1(c).view(1,-1)\n",
        "    out=self.output(p)\n",
        "    return out\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DicY4CPIy-ok",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "t5Zx3cTSSuW9",
        "colab_type": "code",
        "outputId": "38a7a55c-2df5-4a72-fad1-43ed3fae93cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1679
        }
      },
      "cell_type": "code",
      "source": [
        "### Train the CNN model\n",
        "model=CNNClassifier(len(vocab),50,30,7,2)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01,weight_decay=0)\n",
        "epoch_accuracies = []\n",
        "best_accuracy=0\n",
        "for epoch in range(1000):\n",
        "  i=0\n",
        "  for sentence,labels in zip(sentence_train,label_train):\n",
        "    i=i+1\n",
        "    optimizer.zero_grad()\n",
        "    outputs=model(sentence)\n",
        "    labels=labels.unsqueeze(dim=0)\n",
        "    loss=loss_function(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1)%1000==0:\n",
        "              print ('Epoch: [%d/%d], Step: [%d/%d] , Loss: %.4f, Dev: %.4f' \n",
        "                     % (epoch+1, 1000, i+1, len(sentence_train)//32, \n",
        "                        loss.data, accuracy(sentence_train,label_train,model)))\n",
        "  epoch_accuracies.append(accuracy(sentence_test,label_test,model))\n",
        "  if epoch_accuracies[-1] > best_accuracy:\n",
        "    best_accuracy = epoch_accuracies[-1]\n",
        "    best_epoch = epoch\n",
        "    \n",
        "  if(epoch>=10 and epoch_accuracies[-1]<=epoch_accuracies[-10]):\n",
        "    break                \n",
        "  # TODO: implement early stopping here      \n",
        "  print(best_accuracy, best_epoch)\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/1000], Step: [1000/187] , Loss: 2.0960, Dev: 0.2286\n",
            "Epoch: [1/1000], Step: [2000/187] , Loss: 1.0804, Dev: 0.2938\n",
            "Epoch: [1/1000], Step: [3000/187] , Loss: 1.9428, Dev: 0.3219\n",
            "Epoch: [1/1000], Step: [4000/187] , Loss: 0.9861, Dev: 0.3725\n",
            "Epoch: [1/1000], Step: [5000/187] , Loss: 1.8771, Dev: 0.3972\n",
            "0.36564171122994654 0\n",
            "Epoch: [2/1000], Step: [1000/187] , Loss: 2.9138, Dev: 0.4051\n",
            "Epoch: [2/1000], Step: [2000/187] , Loss: 0.3437, Dev: 0.4402\n",
            "Epoch: [2/1000], Step: [3000/187] , Loss: 1.1175, Dev: 0.4330\n",
            "Epoch: [2/1000], Step: [4000/187] , Loss: 0.6763, Dev: 0.4525\n",
            "Epoch: [2/1000], Step: [5000/187] , Loss: 1.8149, Dev: 0.4631\n",
            "0.38636363636363635 1\n",
            "Epoch: [3/1000], Step: [1000/187] , Loss: 1.8063, Dev: 0.4549\n",
            "Epoch: [3/1000], Step: [2000/187] , Loss: 0.1651, Dev: 0.4703\n",
            "Epoch: [3/1000], Step: [3000/187] , Loss: 1.4583, Dev: 0.4855\n",
            "Epoch: [3/1000], Step: [4000/187] , Loss: 1.0886, Dev: 0.4908\n",
            "Epoch: [3/1000], Step: [5000/187] , Loss: 0.9196, Dev: 0.5037\n",
            "0.3997326203208556 2\n",
            "Epoch: [4/1000], Step: [1000/187] , Loss: 2.8534, Dev: 0.4815\n",
            "Epoch: [4/1000], Step: [2000/187] , Loss: 0.0426, Dev: 0.5008\n",
            "Epoch: [4/1000], Step: [3000/187] , Loss: 1.1344, Dev: 0.5052\n",
            "Epoch: [4/1000], Step: [4000/187] , Loss: 1.3223, Dev: 0.5165\n",
            "Epoch: [4/1000], Step: [5000/187] , Loss: 0.2222, Dev: 0.5299\n",
            "0.41310160427807485 3\n",
            "Epoch: [5/1000], Step: [1000/187] , Loss: 3.3613, Dev: 0.5114\n",
            "Epoch: [5/1000], Step: [2000/187] , Loss: 0.1496, Dev: 0.5343\n",
            "Epoch: [5/1000], Step: [3000/187] , Loss: 0.3762, Dev: 0.5307\n",
            "Epoch: [5/1000], Step: [4000/187] , Loss: 0.9659, Dev: 0.5348\n",
            "Epoch: [5/1000], Step: [5000/187] , Loss: 0.1964, Dev: 0.5398\n",
            "0.41310160427807485 3\n",
            "Epoch: [6/1000], Step: [1000/187] , Loss: 2.8600, Dev: 0.5227\n",
            "Epoch: [6/1000], Step: [2000/187] , Loss: 0.1207, Dev: 0.5406\n",
            "Epoch: [6/1000], Step: [3000/187] , Loss: 1.4946, Dev: 0.5419\n",
            "Epoch: [6/1000], Step: [4000/187] , Loss: 0.6857, Dev: 0.5441\n",
            "Epoch: [6/1000], Step: [5000/187] , Loss: 0.6027, Dev: 0.5386\n",
            "0.41310160427807485 3\n",
            "Epoch: [7/1000], Step: [1000/187] , Loss: 3.2019, Dev: 0.5393\n",
            "Epoch: [7/1000], Step: [2000/187] , Loss: 0.1245, Dev: 0.5513\n",
            "Epoch: [7/1000], Step: [3000/187] , Loss: 2.4742, Dev: 0.5655\n",
            "Epoch: [7/1000], Step: [4000/187] , Loss: 1.2641, Dev: 0.5573\n",
            "Epoch: [7/1000], Step: [5000/187] , Loss: 0.7675, Dev: 0.5516\n",
            "0.41310160427807485 3\n",
            "Epoch: [8/1000], Step: [1000/187] , Loss: 2.4646, Dev: 0.5704\n",
            "Epoch: [8/1000], Step: [2000/187] , Loss: 0.0706, Dev: 0.5744\n",
            "Epoch: [8/1000], Step: [3000/187] , Loss: 2.4473, Dev: 0.5725\n",
            "Epoch: [8/1000], Step: [4000/187] , Loss: 1.0888, Dev: 0.5705\n",
            "Epoch: [8/1000], Step: [5000/187] , Loss: 0.3028, Dev: 0.5640\n",
            "0.4244652406417112 7\n",
            "Epoch: [9/1000], Step: [1000/187] , Loss: 2.6592, Dev: 0.5775\n",
            "Epoch: [9/1000], Step: [2000/187] , Loss: 0.0752, Dev: 0.5772\n",
            "Epoch: [9/1000], Step: [3000/187] , Loss: 1.9324, Dev: 0.5704\n",
            "Epoch: [9/1000], Step: [4000/187] , Loss: 0.4720, Dev: 0.5647\n",
            "Epoch: [9/1000], Step: [5000/187] , Loss: 0.1637, Dev: 0.5842\n",
            "0.42513368983957217 8\n",
            "Epoch: [10/1000], Step: [1000/187] , Loss: 4.0247, Dev: 0.5839\n",
            "Epoch: [10/1000], Step: [2000/187] , Loss: 0.0566, Dev: 0.5902\n",
            "Epoch: [10/1000], Step: [3000/187] , Loss: 1.9538, Dev: 0.5881\n",
            "Epoch: [10/1000], Step: [4000/187] , Loss: 0.5105, Dev: 0.5707\n",
            "Epoch: [10/1000], Step: [5000/187] , Loss: 0.1922, Dev: 0.5927\n",
            "0.42513368983957217 8\n",
            "Epoch: [11/1000], Step: [1000/187] , Loss: 4.5884, Dev: 0.6006\n",
            "Epoch: [11/1000], Step: [2000/187] , Loss: 0.1455, Dev: 0.5966\n",
            "Epoch: [11/1000], Step: [3000/187] , Loss: 2.2280, Dev: 0.6001\n",
            "Epoch: [11/1000], Step: [4000/187] , Loss: 0.2772, Dev: 0.5844\n",
            "Epoch: [11/1000], Step: [5000/187] , Loss: 0.0593, Dev: 0.5991\n",
            "0.42513368983957217 8\n",
            "Epoch: [12/1000], Step: [1000/187] , Loss: 5.0123, Dev: 0.6038\n",
            "Epoch: [12/1000], Step: [2000/187] , Loss: 0.0464, Dev: 0.6083\n",
            "Epoch: [12/1000], Step: [3000/187] , Loss: 2.3602, Dev: 0.6223\n",
            "Epoch: [12/1000], Step: [4000/187] , Loss: 0.5799, Dev: 0.5953\n",
            "Epoch: [12/1000], Step: [5000/187] , Loss: 0.0367, Dev: 0.6205\n",
            "0.42780748663101603 11\n",
            "Epoch: [13/1000], Step: [1000/187] , Loss: 4.1980, Dev: 0.6215\n",
            "Epoch: [13/1000], Step: [2000/187] , Loss: 0.0069, Dev: 0.6098\n",
            "Epoch: [13/1000], Step: [3000/187] , Loss: 1.5934, Dev: 0.6310\n",
            "Epoch: [13/1000], Step: [4000/187] , Loss: 0.4006, Dev: 0.6028\n",
            "Epoch: [13/1000], Step: [5000/187] , Loss: 0.0863, Dev: 0.6272\n",
            "0.42780748663101603 11\n",
            "Epoch: [14/1000], Step: [1000/187] , Loss: 3.5569, Dev: 0.6258\n",
            "Epoch: [14/1000], Step: [2000/187] , Loss: 0.0096, Dev: 0.6300\n",
            "Epoch: [14/1000], Step: [3000/187] , Loss: 1.8849, Dev: 0.6330\n",
            "Epoch: [14/1000], Step: [4000/187] , Loss: 0.1996, Dev: 0.6085\n",
            "Epoch: [14/1000], Step: [5000/187] , Loss: 0.2038, Dev: 0.6285\n",
            "0.42780748663101603 11\n",
            "Epoch: [15/1000], Step: [1000/187] , Loss: 2.9276, Dev: 0.6310\n",
            "Epoch: [15/1000], Step: [2000/187] , Loss: 0.0047, Dev: 0.6308\n",
            "Epoch: [15/1000], Step: [3000/187] , Loss: 1.6945, Dev: 0.6399\n",
            "Epoch: [15/1000], Step: [4000/187] , Loss: 0.1095, Dev: 0.6250\n",
            "Epoch: [15/1000], Step: [5000/187] , Loss: 0.1629, Dev: 0.6446\n",
            "0.42780748663101603 11\n",
            "Epoch: [16/1000], Step: [1000/187] , Loss: 4.0544, Dev: 0.6414\n",
            "Epoch: [16/1000], Step: [2000/187] , Loss: 0.0018, Dev: 0.6394\n",
            "Epoch: [16/1000], Step: [3000/187] , Loss: 1.6918, Dev: 0.6404\n",
            "Epoch: [16/1000], Step: [4000/187] , Loss: 0.3365, Dev: 0.6380\n",
            "Epoch: [16/1000], Step: [5000/187] , Loss: 0.2008, Dev: 0.6531\n",
            "0.42780748663101603 11\n",
            "Epoch: [17/1000], Step: [1000/187] , Loss: 3.1367, Dev: 0.6439\n",
            "Epoch: [17/1000], Step: [2000/187] , Loss: 0.0025, Dev: 0.6305\n",
            "Epoch: [17/1000], Step: [3000/187] , Loss: 1.4755, Dev: 0.6467\n",
            "Epoch: [17/1000], Step: [4000/187] , Loss: 0.1859, Dev: 0.6385\n",
            "Epoch: [17/1000], Step: [5000/187] , Loss: 0.2831, Dev: 0.6557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "puB-QFFUHoBf",
        "colab_type": "code",
        "outputId": "908a17e0-4ac5-49e6-9478-3166ee427c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "metrics(sentence_test,label_test,model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1:[0.48648649 0.50869565 0.31602709 0.492      0.37113402 0.28762542\n",
            " 0.3847981 ]\n",
            "recall_score:[0.55450237 0.52232143 0.30701754 0.55156951 0.37305699 0.2160804\n",
            " 0.37155963]\n",
            "precision_score:[0.43333333 0.49576271 0.3255814  0.44404332 0.36923077 0.43\n",
            " 0.39901478]\n",
            "F1_toal:0.4066809664482492\n",
            "rscore_total:0.41372969695457257\n",
            "pscore_total:0.41385232991458704\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
